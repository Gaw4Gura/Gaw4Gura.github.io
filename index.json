[{"authors":null,"categories":null,"content":"Shuoyu Wang is a senior student at Northwestern Polytechnical University.\n  Download my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Shuoyu Wang is a senior student at Northwestern Polytechnical University.\n  Download my resumé.","tags":null,"title":"Shuoyu Wang","type":"authors"},{"authors":["Shuoyu Wang"],"categories":["dissertation"],"content":"传统的基于视觉的振动测量方法 在结构安全监测领域，振动测量在预测潜在灾害和对设计维护活动的结构参数估计方面都起着至关重要的作用。大量的监测技术可用于结构振动监测，而应用最广泛的可能是基于加速度计的测量和形变估计。虽然这些技术适用于大多数应用，但它们在特定应用中存在一些限制，例如在钢梁这样细长的结构中，非接触式测量技术将是首选。这样可以避免负载效应，并可以使得振动的测量在许多方位同时进行。基于视觉的振动测量有许多好处，例如可以在不使用插值的情况下测量振动最大或是最小的点，并且只要结构仍然落在相机镜头内也不需要改变试验设备的位置 [1].\n[1]中介绍了一种由单个传感器（相机）进行监控的基于视觉的细长结构阻尼振动的测量方案。该工作使用边缘检测的方法来识别电缆结构，其中，“边缘”在灰度图像中可以被定义为灰度突变的像素点的集合。考虑到待测量振动的物体通常是一体的，该方法可以被推广到更一般的物体的振动测量中。文章中提到的方法在实践里有两个要求：\n 摄像机应该与待测物体平行 摄像机的采样频率应该至少为电缆阻尼振动频率的两倍，即采样定理  采集到图像以后，系统通过五个步骤来得到电缆阻尼振动的估计：\n 电缆的边缘像素由每一帧图像进行边缘检测获得 通过对像素坐标进行线性拟合来消除数据中的噪声以及量化误差的影响 迭代以上两步，直到电缆边缘所有像素的坐标 在时域中重建每个点的垂直位移 对信号进行傅里叶变换，并在频域中估计每个点的水平位移  图1展示了这个系统的工作原理。\n   [2]介绍了基于多台摄像头和一台笔记本电脑的桥梁结构监测系统。通过摄像头捕捉桥梁结构的边缘和铆钉等标志物，并且通过一种被称为方向码匹配（Orientation Code Matching, OCM）的算法进行视频处理。该算法基于匹配梯度信息，围绕每个像素以方向码的形式计算，而不是直接计算灰度级来进行边缘检测。对于像素$I(x,y)$，其水平和垂直方向的方向导数分别为$\\nabla I_{x}=\\frac{\\partial I}{\\partial x},\\nabla I_{y}=\\frac{\\partial I}{\\partial y}$.使用$\\tan^{-1}(\\nabla I_{y}/\\nabla I_{x})$定义$I(x,y)$的方位角，通过灰度阈值$\\Gamma$，可以得到方向角的高斯表示。随后，可以利用测量函数对方向码进行匹配和测量。在使用振动的桌子对系统进行测试的时候，预先设计的黑白目标面板（216 mm × 280 mm）固定在电磁振动台上，传统方法安装在振动台和固定参考点之间。在距振动台 5.5 米的静止位置放置一个带有 75 毫米镜头的摄像机。相机以每秒 60 帧的速度捕捉目标面板，并通过在连接的计算机上执行 OCM 技术和像素级分析来检测目标面板的位移。在测量之前，使用预先设计的目标面板测量数字图像的实际像素大小。像素的尺寸校准为 0.54 毫米/像素，测量误差的理论值为 0.27 毫米 [2]。在实际应用中，还应该考虑自然环境对系统的影响。\n[3]利用振动学的基础知识（杨氏模量等）和机器视觉检测物体的细微运动，并从中推断物体的材料特性。[4] (1993)则介绍了递归神经网络（RNN）在检测轴承运动中的应用。[5]提出了一种基于多摄像头系统的多散斑匹配（multi speckle matching）方法，采用该方法计算不同相机坐标的旋转矩阵和平移矩阵。 将所有相机的测量点转换为相同的坐标系并构建 3D 形状。 通过减去平移前后的坐标得到全场位移。 使用多相机系统进行铝板测量。结果表明位移场转换误差小于0.1mm。\n新型基于深度学习的位移与振动测量方法 [6]介绍了一个基于YOLO v3$^{*}$的社交距离测量方案。该方案以摄像头的视频帧为输入，采用基于YOLO v3算法的开源物体检测预训练模型进行行人检测。随后，视频帧被转换为自上而下的视图，用于与 2D平面的距离测量，以估计人与人之间的距离。图2展示了这个算法的流程图：\n   利用经过COCO数据集（含有人类以及行人类别）训练的YOLO v3网络对行人进行目标识别，得到行人的bounding_box的中心坐标$(x,y)$，宽高$(w,h)$，目标置信度以及类别标签。尽管YOLO v3可以进行多种目标的检测，但是在本文的工作中，系统将忽略其余目标物，只关注行人类别的对象。\n   街道图像的专注区域（region of interest, ROI）被转换为包含480×480像素的自上而下的2D视图，如图3所示。通过应用相机视图校准，计算透视图变成自上而下的视图。在OpenCV中，透视变换是一种简单的相机校准方法，它涉及在透视图中选择四个点并将它们映射到2D图像视图中的矩形的角上。 假设每个人都站在同一水平平面上。行人之间的实际距离对应于自顶向下视图中的像素数可以估计。最后，利用两个行人的bounding_box中心的距离$d=\\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}$以及相机的缩放倍数可以计算得到行人之间的社交距离。\n[7]则介绍了基于Mask R-CNN$^{*}$的在实验室实验中自动跟踪和测量结构试件位移和振动的系统。Mask R-CNN可以从固定摄像机录制的视频中定位目标并监控其运动。 为了提高精度和去除噪声，包括了尺度不变特征变换（Scale-invariant Feature Transform, SIFT）和各种用于信号处理的滤波器等技术。作者利用三个小型钢筋混凝土梁的试验和振动台试验来验证所提出的方法。结果表明，所提出的深度学习方法可以实现在实验室实验中自动精确测量被测结构构件的运动的目标。图4为这种Mask R-CNN的结构：\n   图5展示了该算法的流程图：\n   不妨令$d_{u}^{j},d_{v}^{j}$表示第一帧物体的bounding_box和第$j$帧物体的bounding_box之间水平以及竖直方向上的位移分量，$s$表示从像素转化为长度单位的比例，则物体的实际位移可以表示为$d_{x}^{j}=s\\cdot d_{u}^{j}$以及$d_{y}^{j}=s\\cdot d_{v}^{j}$.其中，当bounding_box不能很好地拟合物体的实际边框时，作者利用SIFT算法将bounding_box重新与物体进行匹配。图6阐明了该算法的工作原理。\n   $^{*}$：关于YOLO v3等用于实现目标识别或边缘检测的神经网络结构将在之后的文章中学习与介绍。\nConclusion 根据文献[1 \u0026ndash; 7]，基于视觉的振动和位移测量具有广阔的应用空间，并在表现上优于传统方法。而根据[6], [7]，基于深度学习的方法又在基于传统计算机视觉的方法上更进一步。除了上述文献，图像处理技术（image processing technique）[8]，上采样互相关技术（up-sampled cross correlation）[9]，自适应关注区域算法（adaptive Region of Interest algorithm）[10]，改进的泰勒近似（modified Taylor approximation）[11]，使用加速鲁棒特征（Speeded-Up Robust Features, SURF）的轮廓提取[12]等技术[13 \u0026ndash; 20]也需要进一步的学习与研究。\nReferences [1] G. Busca, A. Cigada, A. Manenti and E. Zappa, \u0026ldquo;Vision-based measurements for slender structures vibration monitoring,\u0026rdquo; 2009 IEEE Workshop on Environmental, Energy, and Structural Monitoring Systems, 2009, pp. 98-102, doi: 10.1109/EESMS.2009.5341309.\n[2] Y. Fukuda, M. Q. Feng, Y. Narita, S. Kaneko and T. Tanaka, \u0026ldquo;Vision-Based Displacement Sensor for Monitoring Dynamic Response Using Robust Object Search Algorithm,\u0026rdquo; in IEEE Sensors Journal, vol. 13, no. 12, pp. 4725-4732, Dec. 2013, doi: 10.1109/JSEN.2013.2273309.\n[3] A. Davis, K. L. Bouman, J. G. Chen, M. Rubinstein, F. Durand and W. T. Freeman, \u0026ldquo;Visual vibrometry: Estimating material properties from small motions in video,\u0026rdquo; 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 5335-5343, doi: 10.1109/CVPR.2015.7299171.\n[4] I. E. Alguindigue, A. Loskiewicz-Buczak and R. E. Uhrig, \u0026ldquo;Monitoring and diagnosis of rolling element bearings using artificial neural networks,\u0026rdquo; in IEEE Transactions on Industrial Electronics, vol. 40, no. 2, pp. 209-217, April 1993, doi: 10.1109/41.222642.\n[5] T. Hu, L. Ma, D. Jiang and Q. Fei, \u0026ldquo;Multi-camera based full-field 3D displacement measurement using digital image correlation,\u0026rdquo; 2020 13th International Symposium on Computational Intelligence and Design (ISCID), 2020, pp. 164-167, doi: 10.1109/ISCID51228.2020.00043.\n[6] Y. C. Hou, M. Z. Baharuddin, S. Yussof and S. Dzulkifly, \u0026ldquo;Social Distancing Detection with Deep Learning Model,\u0026rdquo; 2020 8th International Conference on Information Technology and Multimedia (ICIMU), 2020, pp. 334-338, doi: 10.1109/ICIMU49871.2020.9243478.\n[7] Y. Bai, R. M. Abduallah, H. Sezen and A. Yilmaz, \u0026ldquo;Automatic Displacement and Vibration Measurement in Laboratory Experiments with A Deep Learning Method,\u0026rdquo; 2021 IEEE Sensors, 2021, pp. 1-4, doi: 10.1109/SENSORS47087.2021.9639455.\n[8] J.-J. Lee and M. Shinozuka, \u0026ldquo;Real-time displacement measurement of a flexible bridge using digital image processing techniques\u0026rdquo;, Experimental mechanics, vol. 46, no. 1, pp. 105-114, 2006.\n[9] D. Feng, M. Q. Feng, E. Ozer and Y. Fukuda, \u0026ldquo;A vision-based sensor for noncontact structural displacement measurement\u0026rdquo;, Sensors, vol. 15, no. 7, pp. 16557-16575, 2015.\n[10] J. Lee, K.-C. Lee, S. Cho and S.-H. Sim, \u0026ldquo;Computer vision-based structural displacement measurement robust to light-induced image degradation for in-service bridges\u0026rdquo;, Sensors, vol. 17, no. 10, pp. 2317, 2017.\n[11] B. Liu, D. Zhang and J. Guo, \u0026ldquo;Vision-based displacement measurement sensor using modified taylor approximation approach\u0026rdquo;, Optical Engineering, vol. 55, no. 11, pp. 114103, 2016.\n[12] Z. Yin, C. Wu and G. Chen, \u0026ldquo;Concrete crack detection through full-field displacement and curvature measurements by visual mark tracking: A proof-of-concept study\u0026rdquo;, Structural Health Monitoring, vol. 13, no. 2, pp. 205-218, 2014.\n[13] J. Guo and C. Zhu, \u0026ldquo;Dynamic displacement measurement of largescale structures based on the lucas–kanade template tracking algorithm\u0026rdquo;, Mechanical Systems and Signal Processing, vol. 66, pp. 425-436, 2016.\n[14] C.-Z. Dong, O. Celik and F. N. Catbas, \u0026ldquo;Marker-free monitoring of the grandstand structures and modal identification using computer vision methods\u0026rdquo;, Structural Health Monitoring, vol. 18, no. 5-6, pp. 1491-1509, 2019.\n[15] J. Hu and P. F. Pai, \u0026ldquo;Experimental study of resonant vibrations of suspended steel cables using a 3d motion analysis system\u0026rdquo;, Journal of Engineering Mechanics, vol. 138, no. 6, pp. 640-661, 2012.\n[16] J. G. Chen, A. Davis, N. Wadhwa, F. Durand, W. T. Freeman and O. Büyüköztürk, \u0026ldquo;Video camera–based vibration measurement for civil infrastructure applications\u0026rdquo;, Journal of Infrastructure Systems, vol. 23, no. 3, pp. B4016013, 2017.\n[17] V. Hoskere, J.-W. Park, H. Yoon and B. F. Spencer, \u0026ldquo;Vision-based modal survey of civil infrastructure using unmanned aerial vehicles\u0026rdquo;, Journal of Structural Engineering, vol. 145, no. 7, pp. 04019062, 2019.\n[18] C.-Z. Dong, O. Celik, F. N. Catbas, E. J. O’Brien and S. Taylor, \u0026ldquo;Structural displacement monitoring using deep learning-based full field optical flow methods\u0026rdquo;, Structure and Infrastructure Engineering, vol. 16, no. 1, pp. 51-71, 2020.\n[19] C.-Z. Dong and F. N. Catbas, \u0026ldquo;A non-target structural displacement measurement method using advanced feature matching strategy\u0026rdquo;, Advances in Structural Engineering, vol. 22, no. 16, pp. 3461-3472, 2019.\n[20] C.-Z. Dong, O. Celik, F. N. Catbas, E. OBrien and S. Taylor, \u0026ldquo;A robust vision-based method for displacement measurement under adverse environmental factors using spatio-temporal context learning and taylor approximation\u0026rdquo;, Sensors, vol. 19, no. 14, pp. 3197, 2019.\n","date":1641050216,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641050216,"objectID":"fe2309bc74bc01a69688b9bc5f02ae68","permalink":"https://Gaw4Gura.github.io/post/literature_review_1/","publishdate":"2022-01-01T23:16:56+08:00","relpermalink":"/post/literature_review_1/","section":"post","summary":"本文调查了已有的一些基于计算机视觉的微小振动检测方法，其中包括传统方法也包括神经网络方法 。","tags":["displacement and vibration measurement"],"title":"位移检测与振动测量","type":"post"},{"authors":[],"categories":[],"content":"Hello, world! #include \u0026lt;iostream\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026quot;Hello, world!\u0026quot; \u0026lt;\u0026lt; std::endl; return 0; }  ","date":1640875825,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640875825,"objectID":"bdc92b56d808f6c7e15d98d1710a00e2","permalink":"https://Gaw4Gura.github.io/post/hello_world/","publishdate":"2021-12-30T22:50:25+08:00","relpermalink":"/post/hello_world/","section":"post","summary":"Hello, world! #include \u0026lt;iostream\u0026gt; int main() { std::cout \u0026lt;\u0026lt; \u0026quot;Hello, world!\u0026quot; \u0026lt;\u0026lt; std::endl; return 0; }  ","tags":[],"title":"Hello_world","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://Gaw4Gura.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]