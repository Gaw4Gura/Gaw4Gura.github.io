[{"authors":null,"categories":null,"content":"Shuoyu Wang is a senior student at Northwestern Polytechnical University.\n  Download my resumé.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Shuoyu Wang is a senior student at Northwestern Polytechnical University.\n  Download my resumé.","tags":null,"title":"Shuoyu Wang","type":"authors"},{"authors":["Shuoyu Wang"],"categories":["analog-to-digital converter"],"content":"As one mentioned in the previous post, the transfer function of a switched-capacitor circuit is $H(z)=\\frac{1}{z-1}$, which is easy to implement by a Discrete Transfer Fcn module in the MATLAB SIMULINK. One can build an 1-bit switched-capacitor S/H circuit with a feedback gain of -1 as follows.\n   Here, one employs a zero-order hold module to simulate the oversampling procedure.\nOne assumes that the input sine signal has a frequency of 1 rad/sec, the following figure shows the result of the S/H circuit.\n   As one may see, the approximation is literally not accurate. However, as one enable the zero-order hold (the oversampling rate is 4, i.e. $\\frac{1}{4f}=\\frac{1}{4\\times 2\\pi}$), one will find the measurements become more precise.\n   To be more specific, one can implement a 8kHz A/D conversion rate $\\Sigma\\Delta$ modulator at a sampling rate of 512kHz.\n      Similarly, one can conduct the behavioral simulation of an incremental data converter as follows.\n   Here, the constant $\\frac{1}{32}=\\frac{1!}{N}\\cdot 2V_{ref}$ and one assumes that this is a 64 clock cycles incremental data converter while the reference voltage is equal to 1V. The following figure describes the result of one\u0026rsquo;s incremental data converter.\n   References  $\\Sigma\\Delta$ modulator, MathWorks Antonio W. A. Soares, Diomadson R. Belforf, Sebastian Y. C. Catunda, and Raimundo C. S. Freire. 2015. Analysis and System-Level Design of a High Resolution Incremental ΣΔ ADC for Biomedical Applications. In Proceedings of the 28th Symposium on Integrated Circuits and Systems Design (SBCCI \u0026lsquo;15). Association for Computing Machinery, New York, NY, USA, Article 36, 1–6. DOI:https://doi.org/10.1145/2800986.2800998  ","date":1641812498,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641812498,"objectID":"af50422615cc52f774a2c9f0fcce5e8f","permalink":"https://Gaw4Gura.github.io/post/idc_simulink_1/","publishdate":"2022-01-10T19:01:38+08:00","relpermalink":"/post/idc_simulink_1/","section":"post","summary":"As one mentioned in the previous post, the transfer function of a switched-capacitor circuit is $H(z)=\\frac{1}{z-1}$, which is easy to implement by a Discrete Transfer Fcn module in the MATLAB SIMULINK.","tags":["simulink","behavioral simulation","switched-capacitor","sigma-delta modulator","incremental converter"],"title":"Implement the Linear-Exponential Incremental Converter in MATLAB SIMULINK Ⅰ","type":"post"},{"authors":["Shuoyu Wang"],"categories":["S/H circuits"],"content":"Sample Phase The following figure demonstrates the equivalent circuit and the thermal noise of the sample phase.   There are six swichtes, each of them has a thermal noise of $kT/C$, so the overall thermal noise is $v_{n,s}^{2}=6\\frac{kT}{C_{in}}$. One chooses the transmission gates as the switches, so the equivalent resistance is $R_{on, eq}=\\frac{1}{\\mu_{n}C_{ox}(W/L)_{N}(V_{DD}-V_{THN})-\\mu_{p}C_{ox}(W/L)_{P}\\vert V_{THP}\\vert}$. Here, one assumes $\\mu_{n}C_{ox}(W/L)_{N}=\\mu_{p}C_{ox}(W/L)_{P}$.\nHold Phase The following figure elaborates the equivalent circuit and the thermal noise of the hold phase.   One assumes $C_{f}=C_{in}$, so the feedback cofficient of the switched-capacitor circuit is $f=\\frac{1}{C_{f}+C_{in}}=1/2$. For long channel devices, $\\gamma=2/3$, so if one assumes the load transistor has the same $g_{m}$ with the input transistor, the thermal noise $dv_{n,noise}^{2}=\\frac{16kT}{3g_{m}}$. The bandwith of the noise is $\\frac{g_{m}}{4C_{L}}$, where the load capacitance $C_{L}=a C_{in}$ (one ignores the input parasitic capacitance $C_{p}$). Here, $a$ is a cofficient related to the speed of the circuit (one assumes $a=1$). The larger the $W/L$ of the input transistor, the larger the $GBW=g_{m}/C_{L}$. Apparently, $R_{on, eq}$ and $C_{in}$ contributes a pole $R_{on,eq}C_{in}$, one assumes $R_{on,eq}C_{in}\\le \\frac{1}{10}\\frac{C_{L}}{g_{m}}$.\nThe following figure illustrates the choice of the capacitance (at 300K, i.e. room temperature) and the magnitude of the direct-current gain of the amplifier.   One assumes the overdrive voltage $V_{eff}=V_{DSAT}=0.2V$ and $t_{setup}=-\\ln\\left(\\frac{1}{2^{10}\\cdot 4}\\right)\\tau$ where $\\tau=R_{on, eq}C$. As $R_{on, eq}=\\frac{1}{10g_{m}}$ and $g_{m}=\\frac{2I_{SS}}{V_{DSAT}}$, so $2I_{SS}=1\\text{mA}$ and $GBW=\\frac{1}{2\\pi}\\frac{g_{m}}{C_{L}}=0.83\\text{GHz}$.\nOne chooses the following structure to meet the demand of 80dB direct-current gain.   One chooses the folded cascode OPAMP for the auxiliary amplifiers.   Because one has not found a 65nm PDK yet, so it is hard for one to calculate the accurate sizes of the MOSFETs. However, one can know that $g_{m1,2}=\\frac{2I_{SS}}{V_{DSAT}}$, so one can work out the sizes of M1 and M2 by $g_{m}=\\sqrt{2\\mu_{p}C_{ox}\\left(\\frac{W}{L}\\right)_{1,2}I_{D}}$. Similarly, one can figure out the sizes of other MOSFETs by $\\left(\\frac{W}{L}\\right)=\\frac{I_{D}}{\\mu C_{ox}V_{eff}^{2}}$.\nConclusion As von Neumann\u0026rsquo;s celebrated quotes, \u0026ldquo;Young man, in mathematics you don\u0026rsquo;t understand things. You just get used to them.\u0026rdquo; In learning the design of analog circuits, one also begins with imitating others' works, and finally figures out one\u0026rsquo;s own designs.\nReferences  SC amplifier for a 14-bit 80MHz pipeline ADC setup period for an ADC  ","date":1641564970,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641564970,"objectID":"f9dce28da33c2c2b5ac5a876b2efc646","permalink":"https://Gaw4Gura.github.io/post/switched-capacitor_2/","publishdate":"2022-01-07T22:16:10+08:00","relpermalink":"/post/switched-capacitor_2/","section":"post","summary":"This post is a summary of the proposed switched-capacitor amplifier for a 10-bit 100MHz oversampling ADC and 25MHz input signal.","tags":["switched-capacitor"],"title":"The Design of the Switched-Capaitor Amplifier","type":"post"},{"authors":["Shuoyu Wang"],"categories":["dissertation"],"content":"任务分析 对于该毕业设计的具体任务，暂时做出如下分析：\n 对待检测目标（以一截钢管代替钢梁）能够实现实时的目标检测与位移测量 考虑到实际应用背景中待检测物体振动频率较快，因此为了准确描绘物体运动，这里有两个要求：  摄像机的帧率（FPS）应该大于物体振动频率的两倍，即采样定理 用于检测物体的算法应该足够快速，能够满足高速摄像机的帧率   考虑到钢管的位移尺度相对较小，因此算法的测量结果误差应该在1mm以内  除此之外，考虑到待检测物体（钢管）并没有通用的数据集，因此需要制作自定义的数据集用以训练神经网络，在这个任务中，大约需要200张左右的图片。\n目标检测：YOLO, MobileNet, 以及Swim Transformer YOLO v3与YOLO tiny YOLO v3是目前主流的基于深度学习的目标检测算法之一，其网络结构如下：   相较于原先的工作采用的Darknet-19，Darknet-53在精准度上有较大的提升；而相较于采用ResNet结构的工作，Darknet-53又在效率上更胜一筹。下图展示了Darknet-53与其他网络结构的对比：   可以看到YOLO v3每秒可以处理78张图片，而Darknet-19每秒可以处理171张图片。下图为YOLO v3网络框图：   YOLO v3通过改变卷积的步长来控制卷积层输出的大小，并使用大尺寸特征图检测小尺寸对象和小尺寸特征图检测大尺寸对象的思想，输出为$N\\times N\\times [3\\times (4+1+80)]$，其中N表示输出图像的大小，为$8\\times 8$，有三个目标框（anchor框），每个anchor框有四个参数：中心位置$x,y$以及宽高$w,h$，除此之外，还有一个置信度和80维的类别向量。另外，YOLO v3还采用了插值上采样和concat（ResNet）等技巧，实现了良好的性能。 在训练部分，YOLO v3的训练方式如下：\n 预测框分为三种：正确、错误、忽略 任取一个标注为ground truth的数据，与生成的预测框计算Intersection over Union (IoU), IoU最大的预测框即为正确，并且一个预测框只能分配给一个标注为ground truth的数据，类别标签为1，其余为0，置信度为1，产生置信度loss、检测框loss和类别loss 除正确的预测框外，与任意一个标注为ground truth的数据的IoU大于0.5的为忽略检测框，不产生loss 除正确的预测框外，与所有标注为ground truth的数据的IoU都小于0.5的为错误检测框，置信度为0，产生置信度loss  此外，YOLO v3的loss函数为一般的交叉熵函数，而优化器可以使用随机梯度下降优化器或是Adam优化器。   上图为YOLO v3 tiny的网络结构，相比于YOLO v3去除了一些特征层，并且只保留两个独立的预测分支，在工程上更为常用，速度也比YOLO v3更快（在1660Ti上实现了100FPS）。\nMobileNet v2 MobileNet v2在v1的基础上进行改进，同样基于深度可分离卷积。深度可分离卷积在Inception卷积的基础上进行构造，将输入进行$1\\times 1$的卷积之后分成若干个$3\\times 3$的卷积，并在最后进行concat.下图展示了深度可分离卷积Xception的结构：   MobileNet v2提出了两个新观点：\n Linear Bottlenecks，用于解决ReLU激活函数$\\max{x, 0}$造成的非线性问题 Inverted residuals，用于提升梯度在乘积层之间的传播能力  下图为MobileNet v2的网络结构：   MobileNet v2仅用CPU就可以实现80ms单张图片的速度。\nSwim Transformer swim transformer是一种通用的用于图像处理的transformer结构，在ImageNet-22k上达到了775.2 image/s的吞吐量，并摘得ImageNet多个项目的statement of the art (SOTA).下图为swim transformer的结构：   将一张图片分割为少量的window，并在每一个window中做transformer的attention操作，并利用一些技巧提升感受野，达到超过ResNet的效果。目标检测也是swim transformer的经典应用之一。 swim transformer也有显著的缺点：\n 训练轮数要求高，收敛慢 对于不同输入尺寸的图片，需要定制transformer结构  下图为vision transformer (ViT)的结构：   将图像分割成$P\\times P$的window，使用全连接层进行patch embedding，加入一维向量表示每个window原本的位置，之后使用multi-head self-attention机制作为网络的主要结构。 与传统的attention机制相比，multi-head self-attention使用若干不同的变换参数，并进行concat操作。 $$\\text{attention}(Q,V,K)=\\text{softmax}\\left(\\frac{QK^{T}}{\\sqrt{d_{k}}}\\right)V$$ $$head_{i}=\\text{attention}(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})$$ $$\\text{multi-head}(Q,K,V)=\\text{concat}(head_{1}, head_{2}, \\dots, head_{h})W^{O}$$\n一种基于CNN的适用于高速摄像机情景的目标检测方案 针对例如1000FPS的高速相机，上述几种神经网络的效率都不足以达到实时检测要求。高速成像的摄像机几乎不会错过待检测物体的运动，具有高时间密度和低延迟等优势，而用于此类场景的神经网络也很难具有较高的计算复杂度和网络深度。[*]中提出了一种基于数据清洗和数据集成的用于识别高速摄像机采集的图像中的对象的神经网络，并且给出了一个训练数据集。下图为该工作的框架：   其中，数据清洗过程旨在去除尽可能多的错误的region of interest (ROI)区域，以减少后续进行目标识别的工作量。文章中提到的算法为根据预训练网络的输出准备一组ROI图像，并使用支持向量机等方法得到一个评分函数，使用这个评分函数来取舍待识别图像的ROI区域，评估的标准包括了像素值的统计量、像素值的空间导数（拉普拉斯算子等）、物体位置的时间导数（加速度等）等。在目标识别的部分，作者将多个ROI输入以提高检测精度，并通过减少现有的目标识别网络的特征层以牺牲网络的泛化能力为代价提高了网络针对某一特定任务的检测速度。最终，该工作满足了1000FPS的高速相机的应用要求。以下两图为实验中该网络结构的表现：     Conclusion 对于传统的CNN网络结构，为了实现高速实时检测物体运动的目标，需要仔细设计数据集以及输入图像处理的手段，减少神经网络的工作量，并且减少CNN卷积层的数量以提高效率（对于一种特定的任务，这样做对识别精度的影响并不大）。此外，swim transformer也是一大可以探究的应用于高速相机图像实时目标识别的选择。\nReferences  YOLO v3 YOLO v3解读 YOLO v3及YOLO v3 tiny YOLO v3 tiny代码及运行效率 MobileNet v2 深度可分离卷积 MobileNet v2解读 swim transformer swim transformer解读 swim transformer实现目标检测 vision transformer multi-head self-attention  [*] S. Namiki, K. Yokoyama, S. Yachida, T. Shibata, H. Miyano and M. Ishikawa, \u0026ldquo;Online Object Recognition Using CNN-based Algorithm on High-speed Camera Imaging: Framework for fast and robust high-speed camera object recognition based on population data cleansing and data ensemble,\u0026rdquo; 2020 25th International Conference on Pattern Recognition (ICPR), 2021, pp. 2025-2032, doi: 10.1109/ICPR48806.2021.9413042.\n","date":1641555181,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641555181,"objectID":"48be23a514d6233f8fc3be8f1461afba","permalink":"https://Gaw4Gura.github.io/post/literature_review_2/","publishdate":"2022-01-07T19:33:01+08:00","relpermalink":"/post/literature_review_2/","section":"post","summary":"本文分析位移检测与振动测量毕业设计的具体任务，并介绍了一些常见的用于目标检测的深度学习网络，并在最后介绍了基于高速摄像机采集图像的一种卷积神经网络。","tags":["YOLO","CNN","High-Speed Camera"],"title":"位移检测与振动测量","type":"post"},{"authors":[],"categories":["S/H circuits"],"content":"Part 1. Background Question 1: Why we need the switched-capacitor circuits?  Conventional amplifiers with resistors have continuous analog inputs and continuous analog output. However, in A/D converters (ADCs), D/A converters (DACs), and other time-discrete circuits, sample and hold (S/H) circuits first sample the amplitude of the input signal in a certain time and hold the measurement until the post-processing is done. On the other hand, the capacitor can restore the amount of charge, so it can be a good candidate for the S/H circuits.\n Question 2: Why we use capacitors instead of resistors?  Considering the capacitance of a switched-capacitor circuit at a sampling rate of $f_{s}$, the equivalent resistance $R_{eq}=1/(f_{s}C)$. Supposing that the $f_{s}=100kHz$ and the $C=0.1pF$, then $R_{eq}=100M\\Omega$, such an enormous resistance can build large time-constant in small area.\n Part 2. The basic principles of the switched-capacitor circuits The following figure shows the two phases of a simplest switched-capacitor circuits.\n   Considering an inverting amplifier circuit with a gain of $-R_{2}/R_{1}$. Dislike a bipolar amplifier, a CMOS amplifier must have a relatively large output impedance to obtain a large gain. However, the existence of $R_{2}$ can reduce the output impedance of the amplifier enormously. Thus, we replace the two resistors with two capacitors ($C_{1}$ and $C_{2}$ representatively), and now the gain of the new circuit should be $-C_{1}/C_{2}$. If we add three switches to the circuit, it can serve as a switched-capacitor circuit. The following figure explains the two phases of the switched-capacitor amplifier.\n   Let\u0026rsquo;s talk about the choice of the switches. The simplest sampling switch is an NMOS transistor. However, the swing of the input voltage can be limited to $V_{DD}/2$. A solution to this problem is change the NMOS transistor into a transmission gate composed of an NMOS transistor and a PMOS transistor by connecting their sources and drains. The equivalent resistance is $\\frac{1}{\\mu_{n}C_{ox}(W/L)_{N}(V_{DD}-V_{THN})-[\\mu_{n}C_{ox}(W/L)_{N}-\\mu_{p}C_{ox}(W/L)_{P}]V_{in}-\\mu_{p}C_{ox}(W/L)_{P}\\vert V_{THP}\\vert}$. Notably, if $\\mu_{n}C_{ox}(W/L)_{N}=\\mu_{p}C_{ox}(W/L)_{P}$, the $R_{on, eq}$ is not related to $V_{in}$.\nFinally, the thermal noise of a sampling switch is $KT/C$.\nPart 3. Switched-Capacitor Integrators The following figure demonstrates the basic principles of a switched-capacitor integrator.\n   As we can see, the transfer function of a switched-capacitor integrator is $$ H(z)=\\frac{z^{-1}}{1-z^{-1}}=\\frac{1}{z-1} $$ Similarly, we can design a switched-capacitor circuits with differential inputs.\n   The following few posts will record my progress of designing such a switched-capacitor integrator step by step.\nReferences   《模拟CMOS集成电路设计》第2版，【美】毕查德·拉扎维 著，陈贵灿 程军 张瑞智 张鸿 译，陈贵灿 审校\n  EE247， UC Berkeley\n  ","date":1641215201,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641215201,"objectID":"6db76a617c51f366555dca968eb782c8","permalink":"https://Gaw4Gura.github.io/post/switched-capacitor_1/","publishdate":"2022-01-03T21:06:41+08:00","relpermalink":"/post/switched-capacitor_1/","section":"post","summary":"This post is an introduction to the background and the principles of a switched-capacitor circuit. The article is organized as follows. The first part answers why we need switched-capacitor circuits and why we use capacitors instead of resistors. The second part introduces two different switched-capacitor circuits and proposes their noises and gains. The final part reports the schematic diagram of an amplifier for a 10-bit S/H circuit.","tags":["switched-capacitor"],"title":"An Introduction to the Switched-Capacitor Amplifier Circuits","type":"post"},{"authors":["Shuoyu Wang"],"categories":["dissertation"],"content":"传统的基于视觉的振动测量方法 在结构安全监测领域，振动测量在预测潜在灾害和对设计维护活动的结构参数估计方面都起着至关重要的作用。大量的监测技术可用于结构振动监测，而应用最广泛的可能是基于加速度计的测量和形变估计。虽然这些技术适用于大多数应用，但它们在特定应用中存在一些限制，例如在钢梁这样细长的结构中，非接触式测量技术将是首选。这样可以避免负载效应，并可以使得振动的测量在许多方位同时进行。基于视觉的振动测量有许多好处，例如可以在不使用插值的情况下测量振动最大或是最小的点，并且只要结构仍然落在相机镜头内也不需要改变试验设备的位置 [1].\n[1]中介绍了一种由单个传感器（相机）进行监控的基于视觉的细长结构阻尼振动的测量方案。该工作使用边缘检测的方法来识别电缆结构，其中，“边缘”在灰度图像中可以被定义为灰度突变的像素点的集合。考虑到待测量振动的物体通常是一体的，该方法可以被推广到更一般的物体的振动测量中。文章中提到的方法在实践里有两个要求：\n 摄像机应该与待测物体平行 摄像机的采样频率应该至少为电缆阻尼振动频率的两倍，即采样定理  采集到图像以后，系统通过五个步骤来得到电缆阻尼振动的估计：\n 电缆的边缘像素由每一帧图像进行边缘检测获得 通过对像素坐标进行线性拟合来消除数据中的噪声以及量化误差的影响 迭代以上两步，直到电缆边缘所有像素的坐标 在时域中重建每个点的垂直位移 对信号进行傅里叶变换，并在频域中估计每个点的水平位移  图1展示了这个系统的工作原理。\n   [2]介绍了基于多台摄像头和一台笔记本电脑的桥梁结构监测系统。通过摄像头捕捉桥梁结构的边缘和铆钉等标志物，并且通过一种被称为方向码匹配（Orientation Code Matching, OCM）的算法进行视频处理。该算法基于匹配梯度信息，围绕每个像素以方向码的形式计算，而不是直接计算灰度级来进行边缘检测。对于像素$I(x,y)$，其水平和垂直方向的方向导数分别为$\\nabla I_{x}=\\frac{\\partial I}{\\partial x},\\nabla I_{y}=\\frac{\\partial I}{\\partial y}$.使用$\\tan^{-1}(\\nabla I_{y}/\\nabla I_{x})$定义$I(x,y)$的方位角，通过灰度阈值$\\Gamma$，可以得到方向角的高斯表示。随后，可以利用测量函数对方向码进行匹配和测量。在使用振动的桌子对系统进行测试的时候，预先设计的黑白目标面板（216 mm × 280 mm）固定在电磁振动台上，传统方法安装在振动台和固定参考点之间。在距振动台 5.5 米的静止位置放置一个带有 75 毫米镜头的摄像机。相机以每秒 60 帧的速度捕捉目标面板，并通过在连接的计算机上执行 OCM 技术和像素级分析来检测目标面板的位移。在测量之前，使用预先设计的目标面板测量数字图像的实际像素大小。像素的尺寸校准为 0.54 毫米/像素，测量误差的理论值为 0.27 毫米 [2]。在实际应用中，还应该考虑自然环境对系统的影响。\n[3]利用振动学的基础知识（杨氏模量等）和机器视觉检测物体的细微运动，并从中推断物体的材料特性。[4] (1993)则介绍了递归神经网络（RNN）在检测轴承运动中的应用。[5]提出了一种基于多摄像头系统的多散斑匹配（multi speckle matching）方法，采用该方法计算不同相机坐标的旋转矩阵和平移矩阵。 将所有相机的测量点转换为相同的坐标系并构建 3D 形状。 通过减去平移前后的坐标得到全场位移。 使用多相机系统进行铝板测量。结果表明位移场转换误差小于0.1mm。\n新型基于深度学习的位移与振动测量方法 [6]介绍了一个基于YOLO v3$^{*}$的社交距离测量方案。该方案以摄像头的视频帧为输入，采用基于YOLO v3算法的开源物体检测预训练模型进行行人检测。随后，视频帧被转换为自上而下的视图，用于与 2D平面的距离测量，以估计人与人之间的距离。图2展示了这个算法的流程图：\n   利用经过COCO数据集（含有人类以及行人类别）训练的YOLO v3网络对行人进行目标识别，得到行人的bounding_box的中心坐标$(x,y)$，宽高$(w,h)$，目标置信度以及类别标签。尽管YOLO v3可以进行多种目标的检测，但是在本文的工作中，系统将忽略其余目标物，只关注行人类别的对象。\n   街道图像的专注区域（region of interest, ROI）被转换为包含480×480像素的自上而下的2D视图，如图3所示。通过应用相机视图校准，计算透视图变成自上而下的视图。在OpenCV中，透视变换是一种简单的相机校准方法，它涉及在透视图中选择四个点并将它们映射到2D图像视图中的矩形的角上。 假设每个人都站在同一水平平面上。行人之间的实际距离对应于自顶向下视图中的像素数可以估计。最后，利用两个行人的bounding_box中心的距离$d=\\sqrt{(x_{1}-x_{2})^{2}+(y_{1}-y_{2})^{2}}$以及相机的缩放倍数可以计算得到行人之间的社交距离。\n[7]则介绍了基于Mask R-CNN$^{*}$的在实验室实验中自动跟踪和测量结构试件位移和振动的系统。Mask R-CNN可以从固定摄像机录制的视频中定位目标并监控其运动。 为了提高精度和去除噪声，包括了尺度不变特征变换（Scale-invariant Feature Transform, SIFT）和各种用于信号处理的滤波器等技术。作者利用三个小型钢筋混凝土梁的试验和振动台试验来验证所提出的方法。结果表明，所提出的深度学习方法可以实现在实验室实验中自动精确测量被测结构构件的运动的目标。图4为这种Mask R-CNN的结构：\n   图5展示了该算法的流程图：\n   不妨令$d_{u}^{j},d_{v}^{j}$表示第一帧物体的bounding_box和第$j$帧物体的bounding_box之间水平以及竖直方向上的位移分量，$s$表示从像素转化为长度单位的比例，则物体的实际位移可以表示为$d_{x}^{j}=s\\cdot d_{u}^{j}$以及$d_{y}^{j}=s\\cdot d_{v}^{j}$.其中，当bounding_box不能很好地拟合物体的实际边框时，作者利用SIFT算法将bounding_box重新与物体进行匹配。图6阐明了该算法的工作原理。\n   $^{*}$：关于YOLO v3等用于实现目标识别或边缘检测的神经网络结构将在之后的文章中学习与介绍。\nConclusion 根据文献[1 \u0026ndash; 7]，基于视觉的振动和位移测量具有广阔的应用空间，并在表现上优于传统方法。而根据[6], [7]，基于深度学习的方法又在基于传统计算机视觉的方法上更进一步。除了上述文献，图像处理技术（image processing technique）[8]，上采样互相关技术（up-sampled cross correlation）[9]，自适应关注区域算法（adaptive Region of Interest algorithm）[10]，改进的泰勒近似（modified Taylor approximation）[11]，使用加速鲁棒特征（Speeded-Up Robust Features, SURF）的轮廓提取[12]等技术[13 \u0026ndash; 20]也需要进一步的学习与研究。\nReferences [1] G. Busca, A. Cigada, A. Manenti and E. Zappa, \u0026ldquo;Vision-based measurements for slender structures vibration monitoring,\u0026rdquo; 2009 IEEE Workshop on Environmental, Energy, and Structural Monitoring Systems, 2009, pp. 98-102, doi: 10.1109/EESMS.2009.5341309.\n[2] Y. Fukuda, M. Q. Feng, Y. Narita, S. Kaneko and T. Tanaka, \u0026ldquo;Vision-Based Displacement Sensor for Monitoring Dynamic Response Using Robust Object Search Algorithm,\u0026rdquo; in IEEE Sensors Journal, vol. 13, no. 12, pp. 4725-4732, Dec. 2013, doi: 10.1109/JSEN.2013.2273309.\n[3] A. Davis, K. L. Bouman, J. G. Chen, M. Rubinstein, F. Durand and W. T. Freeman, \u0026ldquo;Visual vibrometry: Estimating material properties from small motions in video,\u0026rdquo; 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 5335-5343, doi: 10.1109/CVPR.2015.7299171.\n[4] I. E. Alguindigue, A. Loskiewicz-Buczak and R. E. Uhrig, \u0026ldquo;Monitoring and diagnosis of rolling element bearings using artificial neural networks,\u0026rdquo; in IEEE Transactions on Industrial Electronics, vol. 40, no. 2, pp. 209-217, April 1993, doi: 10.1109/41.222642.\n[5] T. Hu, L. Ma, D. Jiang and Q. Fei, \u0026ldquo;Multi-camera based full-field 3D displacement measurement using digital image correlation,\u0026rdquo; 2020 13th International Symposium on Computational Intelligence and Design (ISCID), 2020, pp. 164-167, doi: 10.1109/ISCID51228.2020.00043.\n[6] Y. C. Hou, M. Z. Baharuddin, S. Yussof and S. Dzulkifly, \u0026ldquo;Social Distancing Detection with Deep Learning Model,\u0026rdquo; 2020 8th International Conference on Information Technology and Multimedia (ICIMU), 2020, pp. 334-338, doi: 10.1109/ICIMU49871.2020.9243478.\n[7] Y. Bai, R. M. Abduallah, H. Sezen and A. Yilmaz, \u0026ldquo;Automatic Displacement and Vibration Measurement in Laboratory Experiments with A Deep Learning Method,\u0026rdquo; 2021 IEEE Sensors, 2021, pp. 1-4, doi: 10.1109/SENSORS47087.2021.9639455.\n[8] J.-J. Lee and M. Shinozuka, \u0026ldquo;Real-time displacement measurement of a flexible bridge using digital image processing techniques\u0026rdquo;, Experimental mechanics, vol. 46, no. 1, pp. 105-114, 2006.\n[9] D. Feng, M. Q. Feng, E. Ozer and Y. Fukuda, \u0026ldquo;A vision-based sensor for noncontact structural displacement measurement\u0026rdquo;, Sensors, vol. 15, no. 7, pp. 16557-16575, 2015.\n[10] J. Lee, K.-C. Lee, S. Cho and S.-H. Sim, \u0026ldquo;Computer vision-based structural displacement measurement robust to light-induced image degradation for in-service bridges\u0026rdquo;, Sensors, vol. 17, no. 10, pp. 2317, 2017.\n[11] B. Liu, D. Zhang and J. Guo, \u0026ldquo;Vision-based displacement measurement sensor using modified taylor approximation approach\u0026rdquo;, Optical Engineering, vol. 55, no. 11, pp. 114103, 2016.\n[12] Z. Yin, C. Wu and G. Chen, \u0026ldquo;Concrete crack detection through full-field displacement and curvature measurements by visual mark tracking: A proof-of-concept study\u0026rdquo;, Structural Health Monitoring, vol. 13, no. 2, pp. 205-218, 2014.\n[13] J. Guo and C. Zhu, \u0026ldquo;Dynamic displacement measurement of largescale structures based on the lucas–kanade template tracking algorithm\u0026rdquo;, Mechanical Systems and Signal Processing, vol. 66, pp. 425-436, 2016.\n[14] C.-Z. Dong, O. Celik and F. N. Catbas, \u0026ldquo;Marker-free monitoring of the grandstand structures and modal identification using computer vision methods\u0026rdquo;, Structural Health Monitoring, vol. 18, no. 5-6, pp. 1491-1509, 2019.\n[15] J. Hu and P. F. Pai, \u0026ldquo;Experimental study of resonant vibrations of suspended steel cables using a 3d motion analysis system\u0026rdquo;, Journal of Engineering Mechanics, vol. 138, no. 6, pp. 640-661, 2012.\n[16] J. G. Chen, A. Davis, N. Wadhwa, F. Durand, W. T. Freeman and O. Büyüköztürk, \u0026ldquo;Video camera–based vibration measurement for civil infrastructure applications\u0026rdquo;, Journal of Infrastructure Systems, vol. 23, no. 3, pp. B4016013, 2017.\n[17] V. Hoskere, J.-W. Park, H. Yoon and B. F. Spencer, \u0026ldquo;Vision-based modal survey of civil infrastructure using unmanned aerial vehicles\u0026rdquo;, Journal of Structural Engineering, vol. 145, no. 7, pp. 04019062, 2019.\n[18] C.-Z. Dong, O. Celik, F. N. Catbas, E. J. O’Brien and S. Taylor, \u0026ldquo;Structural displacement monitoring using deep learning-based full field optical flow methods\u0026rdquo;, Structure and Infrastructure Engineering, vol. 16, no. 1, pp. 51-71, 2020.\n[19] C.-Z. Dong and F. N. Catbas, \u0026ldquo;A non-target structural displacement measurement method using advanced feature matching strategy\u0026rdquo;, Advances in Structural Engineering, vol. 22, no. 16, pp. 3461-3472, 2019.\n[20] C.-Z. Dong, O. Celik, F. N. Catbas, E. OBrien and S. Taylor, \u0026ldquo;A robust vision-based method for displacement measurement under adverse environmental factors using spatio-temporal context learning and taylor approximation\u0026rdquo;, Sensors, vol. 19, no. 14, pp. 3197, 2019.\n","date":1641050216,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641050216,"objectID":"fe2309bc74bc01a69688b9bc5f02ae68","permalink":"https://Gaw4Gura.github.io/post/literature_review_1/","publishdate":"2022-01-01T23:16:56+08:00","relpermalink":"/post/literature_review_1/","section":"post","summary":"本文调查了已有的一些基于计算机视觉的微小振动检测方法，其中包括传统方法也包括神经网络方法 。","tags":["displacement and vibration measurement"],"title":"位移检测与振动测量","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://Gaw4Gura.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]